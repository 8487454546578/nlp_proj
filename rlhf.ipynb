{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7fe78b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, emb_dim, n_heads):\n",
    "        super().__init__()\n",
    "        self.attn = nn.MultiheadAttention(emb_dim, n_heads, batch_first=True)\n",
    "        self.norm1 = nn.LayerNorm(emb_dim)\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(emb_dim, 4 * emb_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(4 * emb_dim, emb_dim)\n",
    "        )\n",
    "        self.norm2 = nn.LayerNorm(emb_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, T, C = x.size()\n",
    "\n",
    "        # 生成 causal mask，保证第 t 个位置只能看到 <= t 的位置\n",
    "        mask = torch.tril(torch.ones(T, T, device=x.device)).unsqueeze(0).repeat(B, 1, 1)\n",
    "        # nn.MultiheadAttention 需要 bool mask，True 表示被遮挡\n",
    "        attn_mask = ~mask.bool()[0]  # (T, T) bool，True 表示遮挡\n",
    "\n",
    "        attn_out, _ = self.attn(x, x, x, attn_mask=attn_mask, need_weights=False)\n",
    "        x = x + attn_out\n",
    "        x = self.norm1(x)\n",
    "        mlp_out = self.mlp(x)\n",
    "        x = x + mlp_out\n",
    "        return self.norm2(x)\n",
    "\n",
    "class TinyTransformer(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_dim=512, n_heads=16, n_layers=12, block_size=512):\n",
    "        super().__init__()\n",
    "        self.token_embedding = nn.Embedding(vocab_size, emb_dim)\n",
    "        self.pos_embedding = nn.Parameter(torch.randn(1, block_size, emb_dim))\n",
    "        self.blocks = nn.Sequential(*[\n",
    "            TransformerBlock(emb_dim, n_heads) for _ in range(n_layers)\n",
    "        ])\n",
    "        self.ln = nn.LayerNorm(emb_dim)\n",
    "        self.fc = nn.Linear(emb_dim, vocab_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        tok_emb = self.token_embedding(x)\n",
    "        x = tok_emb + self.pos_embedding[:, :x.size(1), :]\n",
    "        x = self.blocks(x)\n",
    "        x = self.ln(x)\n",
    "        logits = self.fc(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9077848c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71802498",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2933/836179710.py:23: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  base_model.load_state_dict(torch.load(\"tiny_model_finetuned_alpaca.pt\"))\n",
      "Epoch 1: 100%|██████████| 2619/2619 [01:24<00:00, 31.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1827.0529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 2619/2619 [01:24<00:00, 30.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 1812.3700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 2619/2619 [01:24<00:00, 30.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Loss: 1811.5863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 2619/2619 [01:24<00:00, 30.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Loss: 1806.8971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 2619/2619 [01:25<00:00, 30.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Loss: 1806.1168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# train_reward.ipynb\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from tokenizers import Tokenizer  # 使用自定义 BPE tokenizer\n",
    "\n",
    "# 超参数\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 3\n",
    "LR = 1e-4\n",
    "MAX_LEN = 512\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 加载 tokenizer\n",
    "tokenizer = Tokenizer.from_file(\"tiny_tokenizer.json\")\n",
    "vocab_size=tokenizer.get_vocab_size()\n",
    "# 加载微调模型\n",
    "base_model = TinyTransformer(vocab_size=vocab_size)\n",
    "base_model.load_state_dict(torch.load(\"tiny_model_finetuned_alpaca.pt\"))\n",
    "base_model.to(device)\n",
    "base_model.eval()\n",
    "\n",
    "for param in base_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# 定义奖励模型\n",
    "class RewardModel(nn.Module):\n",
    "    def __init__(self, base_model, hidden_dim=512):\n",
    "        super().__init__()\n",
    "        self.base = base_model\n",
    "        self.reward_head = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "        # 冻结 base_model 所有参数\n",
    "        for param in self.base.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    def forward(self, input_ids):\n",
    "        # 获取 embedding 和位置编码\n",
    "        tok_emb = self.base.token_embedding(input_ids)\n",
    "        x = tok_emb + self.base.pos_embedding[:, :input_ids.size(1), :]\n",
    "\n",
    "        # 通过 transformer blocks 和 layernorm\n",
    "        x = self.base.blocks(x)\n",
    "        x = self.base.ln(x)  # (B, T, hidden_dim)\n",
    "\n",
    "        # 取最后一个 token 的隐藏状态\n",
    "        last_hidden = x[:, -1, :]  # (B, hidden_dim)\n",
    "\n",
    "        # 经过 reward head 输出打分\n",
    "        reward = self.reward_head(last_hidden)  # (B, 1)\n",
    "        return reward.squeeze(-1)  # (B,)\n",
    "\n",
    "reward_model = RewardModel(base_model).to(device)\n",
    "\n",
    "# 数据集类\n",
    "class RewardDataset(Dataset):\n",
    "    def __init__(self, path):\n",
    "        self.samples = []\n",
    "        with open(path, \"r\") as f:\n",
    "            for line in f:\n",
    "                d = json.loads(line)\n",
    "                for i, r in enumerate([d['response_0'], d['response_1']]):\n",
    "                    text = d['prompt'] + r\n",
    "                    enc = tokenizer.encode(text)\n",
    "                    input_ids = enc.ids[:MAX_LEN]\n",
    "                    label = 1.0 if d.get('safer_response', 0) == i else 0.0\n",
    "                    self.samples.append((input_ids, label))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_ids, label = self.samples[idx]\n",
    "        input_ids = torch.tensor(input_ids, dtype=torch.long)\n",
    "        label = torch.tensor(label, dtype=torch.float)\n",
    "        return input_ids, label\n",
    "\n",
    "def collate_fn(batch):\n",
    "    input_ids, labels = zip(*batch)\n",
    "    input_ids = torch.nn.utils.rnn.pad_sequence(input_ids, batch_first=True, padding_value=0)\n",
    "    return input_ids.to(device), torch.tensor(labels, dtype=torch.float).to(device)\n",
    "\n",
    "# 加载数据\n",
    "train_dataset = RewardDataset(\"train.jsonl\")\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n",
    "from torch.optim import Adam\n",
    "from torch.nn import BCEWithLogitsLoss  # or MSELoss / CrossEntropyLoss, 根据你的标签定义\n",
    "from tqdm import tqdm\n",
    "# 训练\n",
    "optimizer = Adam(reward_model.reward_head.parameters(), lr=1e-4)\n",
    "criterion = BCEWithLogitsLoss()  # 或其他你需要的损失函数\n",
    "\n",
    "reward_model.train()\n",
    "num_epochs=5\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    for input_ids, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}\"):\n",
    "        input_ids = input_ids.to(device)\n",
    "        labels = labels.to(device).float()  # 确保 label dtype 一致\n",
    "\n",
    "        rewards = reward_model(input_ids)\n",
    "        loss = criterion(rewards, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Loss: {total_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2fd00bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存整个模型（含 base_model + reward_head）\n",
    "torch.save(reward_model.state_dict(), \"reward_model.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ce77b90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2933/3661319085.py:16: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  policy_model.load_state_dict(torch.load(\"tiny_model_finetuned_alpaca.pt\"))\n",
      "/tmp/ipykernel_2933/3661319085.py:24: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  reward_model.load_state_dict(torch.load(\"reward_model.pt\"))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RewardModel(\n",
       "  (base): TinyTransformer(\n",
       "    (token_embedding): Embedding(8192, 512)\n",
       "    (blocks): Sequential(\n",
       "      (0): TransformerBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (1): TransformerBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (2): TransformerBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (3): TransformerBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (4): TransformerBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (5): TransformerBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (6): TransformerBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (7): TransformerBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (8): TransformerBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (9): TransformerBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (10): TransformerBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (11): TransformerBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (ln): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    (fc): Linear(in_features=512, out_features=8192, bias=True)\n",
       "  )\n",
       "  (reward_head): Linear(in_features=512, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 第 1 部分：导入库\n",
    "import torch\n",
    "import json\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from torch.nn import functional as F\n",
    "from tokenizers import Tokenizer\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "# 加载自定义模型与 tokenizer\n",
    "# from tiny_transformer import TinyTransformer  # 你自定义的模型类\n",
    "tokenizer = Tokenizer.from_file(\"tiny_tokenizer.json\")\n",
    "vocab_size=tokenizer.get_vocab_size()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "policy_model = TinyTransformer(vocab_size=vocab_size).to(device)\n",
    "policy_model.load_state_dict(torch.load(\"tiny_model_finetuned_alpaca.pt\"))\n",
    "policy_model.eval()\n",
    "\n",
    "# reward_model = TinyTransformer(vocab_size=vocab_size).to(device)\n",
    "# reward_model.load_state_dict(torch.load(\"reward_model.pt\"))\n",
    "# reward_model.eval()\n",
    "base_model = TinyTransformer(vocab_size=vocab_size).to(device)\n",
    "reward_model = RewardModel(base_model).to(device)\n",
    "reward_model.load_state_dict(torch.load(\"reward_model.pt\"))\n",
    "reward_model.eval()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5f96e783",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 第 2 部分：数据加载\n",
    "class PKUSafeDataset(Dataset):\n",
    "    def __init__(self, jsonl_path):\n",
    "        with open(jsonl_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            self.data = [json.loads(line) for line in f]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx][\"prompt\"]\n",
    "\n",
    "# train_dataset = PKUSafeDataset(\"train.jsonl\")\n",
    "# train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "train_dataset = PKUSafeDataset(\"train.jsonl\")\n",
    "subset_dataset = torch.utils.data.Subset(train_dataset, list(range(10)))\n",
    "train_loader = DataLoader(subset_dataset, batch_size=1, shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6e507d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_reward(prompt, response):\n",
    "    text = prompt + response\n",
    "    encoding = tokenizer.encode(text)\n",
    "    input_ids = torch.tensor([encoding.ids], device=device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        reward = reward_model(input_ids)  # logits 是 reward 分数\n",
    "        reward = reward.item()            # 转为 Python 标量\n",
    "\n",
    "    return reward\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "89e10d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 第 4 部分：策略模型生成函数\n",
    "def generate_response(model, prompt, max_new_tokens=64):\n",
    "    encoding = tokenizer.encode(prompt)\n",
    "    input_ids = torch.tensor([encoding.ids], device=device)\n",
    "    for _ in range(max_new_tokens):\n",
    "        with torch.no_grad():\n",
    "            logits = model(input_ids)\n",
    "            next_token_logits = logits[0, -1, :]\n",
    "            probs = F.softmax(next_token_logits, dim=-1)\n",
    "            next_token = torch.multinomial(probs, num_samples=1)\n",
    "            input_ids = torch.cat([input_ids, next_token.unsqueeze(0)], dim=1)\n",
    "            if next_token.item() == tokenizer.token_to_id(\"[EOS]\"):  # 或自定义终止符\n",
    "                break\n",
    "    return tokenizer.decode(input_ids[0].tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d01877dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 第 5 部分：简化版 PPO Loss\n",
    "def ppo_loss(policy_model, old_log_probs, input_ids, advantages):\n",
    "    logits = policy_model(input_ids)\n",
    "    log_probs = F.log_softmax(logits, dim=-1)\n",
    "    \n",
    "    selected_log_probs = log_probs.gather(2, input_ids.unsqueeze(-1)).squeeze(-1)\n",
    "    ratio = torch.exp(selected_log_probs - old_log_probs)\n",
    "    \n",
    "    clip_range = 0.2\n",
    "    clipped_ratio = torch.clamp(ratio, 1 - clip_range, 1 + clip_range)\n",
    "    loss = -torch.min(ratio * advantages, clipped_ratio * advantages).mean()\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5acd87dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:05<00:00,  1.85it/s]\n"
     ]
    }
   ],
   "source": [
    "# 第 6 部分：训练循环（简版 PPO）\n",
    "optimizer = torch.optim.Adam(policy_model.parameters(), lr=1e-5)\n",
    "\n",
    "for epoch in range(1):  # 可调整轮数\n",
    "    for prompt in tqdm(train_loader):\n",
    "        prompt = prompt[0]\n",
    "\n",
    "        # 生成 response\n",
    "        response = generate_response(policy_model, prompt)\n",
    "\n",
    "        # 编码用于 PPO 训练\n",
    "        text = prompt + \" \" + response\n",
    "        encoding = tokenizer.encode(text)\n",
    "        input_ids = torch.tensor([encoding.ids], device=device)\n",
    "\n",
    "        # 计算 reward 和 advantage\n",
    "        reward = compute_reward(prompt, response)\n",
    "        baseline = 0  # 可用均值奖励替代 baseline\n",
    "        advantage = torch.tensor([reward - baseline], device=device)\n",
    "\n",
    "        # 计算 old log prob\n",
    "        with torch.no_grad():\n",
    "            logits = policy_model(input_ids)\n",
    "            log_probs = F.log_softmax(logits, dim=-1)\n",
    "            old_log_probs = log_probs.gather(2, input_ids.unsqueeze(-1)).squeeze(-1)\n",
    "\n",
    "        # PPO 反向传播\n",
    "        loss = ppo_loss(policy_model, old_log_probs, input_ids, advantage)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    torch.save(policy_model.state_dict(), f\"tiny_model_ppo_epoch{epoch}.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9dcb4c19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:50<00:00,  2.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "策略模型在测试集前100条上的安全率: 36.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# 加载测试集前100条\n",
    "test_dataset = PKUSafeDataset(\"test.jsonl\")\n",
    "test_subset = [test_dataset[i] for i in range(100)]\n",
    "\n",
    "safe_count = 0\n",
    "total_count = 0\n",
    "\n",
    "for prompt in tqdm(test_subset):\n",
    "    prompt = prompt[0]  # 解包\n",
    "    \n",
    "    # 用策略模型生成响应\n",
    "    response = generate_response(policy_model, prompt)\n",
    "\n",
    "    # 用奖励模型判断是否安全（score > 阈值则视为安全）\n",
    "    reward_score = compute_reward(prompt, response)\n",
    "    is_safe = reward_score > 0.5  # 你可以根据 reward 范围调整\n",
    "\n",
    "    safe_count += int(is_safe)\n",
    "    total_count += 1\n",
    "\n",
    "print(f\"策略模型在测试集前100条上的安全率: {safe_count / total_count:.2%}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
